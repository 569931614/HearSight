"""
çŸ¥è¯†åº“æœåŠ¡

å¤„ç†æ•°æ®åŒæ­¥ã€å‘é‡åº“ç®¡ç†ç­‰
"""
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from backend.knowledge.vector_store import get_vector_store
from backend.knowledge.chat_client import chat_with_rag
from backend.db.pg_store import (
    get_transcript_by_id,
    get_summaries_by_transcript_id,
    list_transcripts_meta,
)

logger = logging.getLogger(__name__)


def sync_transcript_to_vector_db(
    db_url: str,
    transcript_id: int,
    persist_directory: Optional[str] = None
) -> bool:
    """
    å°†è½¬å†™è®°å½•å’Œæ‘˜è¦åŒæ­¥åˆ°å‘é‡åº“

    Args:
        db_url: æ•°æ®åº“è¿æ¥URL
        transcript_id: è½¬å†™è®°å½•ID
        persist_directory: å‘é‡åº“æŒä¹…åŒ–ç›®å½•

    Returns:
        bool: æ˜¯å¦åŒæ­¥æˆåŠŸ
    """
    try:
        # è·å–è½¬å†™è®°å½•
        transcript = get_transcript_by_id(db_url, transcript_id)
        if not transcript:
            logger.warning(f"è½¬å†™è®°å½•ä¸å­˜åœ¨: {transcript_id}")
            return False

        media_path = transcript.get("media_path")
        segments = transcript.get("segments", [])

        if not media_path or not segments:
            logger.warning(f"è½¬å†™è®°å½•æ•°æ®ä¸å®Œæ•´: {transcript_id}")
            return False

        # è·å–æ‘˜è¦
        summaries = get_summaries_by_transcript_id(db_url, transcript_id)
        if not summaries:
            logger.warning(f"æœªæ‰¾åˆ°æ‘˜è¦æ•°æ®: {transcript_id}")
            # å³ä½¿æ²¡æœ‰æ‘˜è¦ï¼Œä¹Ÿå¯ä»¥å­˜å‚¨åŸå§‹ç‰‡æ®µ
            summaries = []

        # è·å–å‘é‡åº“å®ä¾‹
        vector_store = get_vector_store(persist_directory)

        # æ„å»ºæ‘˜è¦æ•°æ®ç»“æ„
        # ä»æ‘˜è¦ä¸­æå–æ•´ä½“ä¸»é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
        topic = "è§†é¢‘å†…å®¹"
        overall_summary = ""
        paragraphs = []

        if summaries:
            # å‡è®¾æ‘˜è¦ç»“æ„ï¼š[{text, summary, start_time, end_time}, ...]
            for summary_item in summaries:
                para_text = summary_item.get("text", "")
                para_summary = summary_item.get("summary", "")
                start_time = summary_item.get("start_time", 0)
                end_time = summary_item.get("end_time", 0)

                paragraphs.append({
                    "text": para_text,
                    "summary": para_summary,
                    "start_time": start_time,
                    "end_time": end_time
                })

            # å°è¯•ä»ç¬¬ä¸€ä¸ªæ‘˜è¦ä¸­æå–ä¸»é¢˜
            if summaries and summaries[0].get("summary"):
                topic = summaries[0].get("summary", "è§†é¢‘å†…å®¹")[:50]  # æˆªå–å‰50å­—ä½œä¸ºä¸»é¢˜

            # ç”Ÿæˆæ•´ä½“æ‘˜è¦
            overall_summary = f"æœ¬è§†é¢‘åŒ…å« {len(summaries)} ä¸ªç‰‡æ®µ"
        else:
            # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œä½¿ç”¨åŸå§‹ç‰‡æ®µ
            for seg in segments:
                para_text = seg.get("text", "")
                start_time = seg.get("start_time", 0)
                end_time = seg.get("end_time", 0)

                paragraphs.append({
                    "text": para_text,
                    "summary": "",
                    "start_time": start_time,
                    "end_time": end_time
                })

            overall_summary = f"æœ¬è§†é¢‘åŒ…å« {len(segments)} ä¸ªè¯­éŸ³ç‰‡æ®µ"

        # è®¡ç®—æ€»æ—¶é•¿
        total_duration = 0
        if paragraphs:
            total_duration = max([p.get("end_time", 0) for p in paragraphs])

        summary = {
            "topic": topic,
            "summary": overall_summary,
            "paragraph_count": len(paragraphs),
            "total_duration": total_duration
        }

        # å­˜å‚¨åˆ°å‘é‡åº“
        success = vector_store.store_summary(
            video_path=media_path,
            summary=summary,
            paragraphs=paragraphs,
            metadata={"transcript_id": transcript_id}
        )

        if success:
            logger.info(f"âœ… æˆåŠŸåŒæ­¥è½¬å†™è®°å½•åˆ°å‘é‡åº“: transcript_id={transcript_id}")
        else:
            logger.error(f"âŒ åŒæ­¥è½¬å†™è®°å½•åˆ°å‘é‡åº“å¤±è´¥: transcript_id={transcript_id}")

        return success

    except Exception as e:
        logger.error(f"âŒ åŒæ­¥å¤±è´¥: transcript_id={transcript_id}, error={e}")
        import traceback
        traceback.print_exc()
        return False


def sync_all_transcripts_to_vector_db(
    db_url: str,
    persist_directory: Optional[str] = None
) -> Dict[str, Any]:
    """
    å°†æ‰€æœ‰è½¬å†™è®°å½•åŒæ­¥åˆ°å‘é‡åº“

    Args:
        db_url: æ•°æ®åº“è¿æ¥URL
        persist_directory: å‘é‡åº“æŒä¹…åŒ–ç›®å½•

    Returns:
        Dict: åŒæ­¥ç»“æœç»Ÿè®¡
    """
    try:
        # è·å–æ‰€æœ‰è½¬å†™è®°å½•
        transcripts = list_transcripts_meta(db_url, limit=1000, offset=0)

        success_count = 0
        failed_count = 0
        failed_ids = []

        for transcript in transcripts:
            transcript_id = transcript.get("id")
            if transcript_id:
                if sync_transcript_to_vector_db(db_url, transcript_id, persist_directory):
                    success_count += 1
                else:
                    failed_count += 1
                    failed_ids.append(transcript_id)

        logger.info(f"âœ… æ‰¹é‡åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")

        return {
            "total": len(transcripts),
            "success": success_count,
            "failed": failed_count,
            "failed_ids": failed_ids
        }

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡åŒæ­¥å¤±è´¥: {e}")
        return {
            "total": 0,
            "success": 0,
            "failed": 0,
            "error": str(e)
        }


def search_knowledge_base(
    query: str,
    n_results: int = 5,
    persist_directory: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    åœ¨çŸ¥è¯†åº“ä¸­æœç´¢

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        n_results: è¿”å›ç»“æœæ•°é‡
        persist_directory: å‘é‡åº“æŒä¹…åŒ–ç›®å½•

    Returns:
        List[Dict]: æœç´¢ç»“æœ
    """
    try:
        vector_store = get_vector_store(persist_directory)
        results = vector_store.search(query, n_results=n_results)

        logger.info(f"ğŸ” æœç´¢å®Œæˆ: query='{query}', ç»“æœæ•°={len(results)}")
        return results

    except Exception as e:
        logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
        return []


def chat_with_knowledge_base(
    query: str,
    api_key: str,
    base_url: str,
    model: str,
    n_results: int = 5,
    persist_directory: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    åŸºäºçŸ¥è¯†åº“çš„å¯¹è¯

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        api_key: LLM APIå¯†é’¥
        base_url: LLM APIåŸºç¡€URL
        model: LLMæ¨¡å‹åç§°
        n_results: æ£€ç´¢ç»“æœæ•°é‡
        persist_directory: å‘é‡åº“æŒä¹…åŒ–ç›®å½•
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        Dict: å¯¹è¯ç»“æœ
    """
    try:
        # 1. æ£€ç´¢ç›¸å…³å†…å®¹
        logger.info(f"ğŸ’¬ å¼€å§‹å¯¹è¯: query='{query}'")
        context_documents = search_knowledge_base(query, n_results, persist_directory)

        if not context_documents:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
            return {
                "answer": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„è§†é¢‘å†…å®¹æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚",
                "references": [],
                "query": query
            }

        # 2. ä½¿ç”¨ RAG ç”Ÿæˆå›ç­”
        result = chat_with_rag(
            query=query,
            context_documents=context_documents,
            api_key=api_key,
            base_url=base_url,
            model=model,
            **kwargs
        )

        logger.info(f"âœ… å¯¹è¯å®Œæˆ: ç­”æ¡ˆé•¿åº¦={len(result.get('answer', ''))}, å¼•ç”¨æ•°={len(result.get('references', []))}")
        return result

    except Exception as e:
        logger.error(f"âŒ å¯¹è¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "answer": f"å¯¹è¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
            "references": [],
            "query": query,
            "error": str(e)
        }


def list_all_videos_in_knowledge_base(
    persist_directory: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰è§†é¢‘

    Args:
        persist_directory: å‘é‡åº“æŒä¹…åŒ–ç›®å½•

    Returns:
        List[Dict]: è§†é¢‘åˆ—è¡¨
    """
    try:
        vector_store = get_vector_store(persist_directory)
        videos = vector_store.list_all_videos()

        logger.info(f"ğŸ“‹ åˆ—å‡ºçŸ¥è¯†åº“è§†é¢‘: å…± {len(videos)} ä¸ª")
        return videos

    except Exception as e:
        logger.error(f"âŒ åˆ—å‡ºè§†é¢‘å¤±è´¥: {e}")
        return []
